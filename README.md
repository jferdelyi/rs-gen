# rs-gen

**rs-gen** is a Rust-based N-gram word generation toolkit composed of a reusable core library, a REST API server, and a lightweight web interface.

---

## üì¶ Workspace structure

`rs-gen` is organized as a Cargo workspace with three crates and a stati website:

```
rs-gen
‚îú‚îÄ‚îÄ rs-core           # Core N-gram and MultiGram generation logic
‚îú‚îÄ‚îÄ rs-server         # REST API server (actix-web)
‚îú‚îÄ‚îÄ rs-exemple        # Minimal API usage examples
‚îî‚îÄ‚îÄ simple-web-front  # Lightweight web-based UI
```

Each crate has a single responsibility and can be used independently.

---

## üß† rs-core

The `rs-core` crate contains **all generation logic**. It is fully deterministic given a seed and parameters, and has **no dependency on networking or UI code**.

### Overview

The generator learns character-level N-gram models from input datasets. After training, it can synthesize new words that statistically resemble the source data while remaining configurable and exploratory.

### Backoff and reduction strategy

During generation, if a key does not exist in the current N-gram model, the generator applies a **progressive backoff strategy**:

1. The key is reduced by one character.
2. The generator retries using the corresponding (N‚àí1)-gram model.
3. This process repeats until a valid transition is found.

This guarantees continuity of generation even in sparse or over-constrained models.

### Multi-model generation (MultiGram)

Each dataset is represented internally as a `MultiGramModel`, which is a **meta-model composed of multiple independent N-gram models**.

Multiple `MultiGramModel`s can be loaded simultaneously. Each model is assigned an **intensity weight**, and the next character is generated by sampling from models according to their **normalized intensities**.

This allows:

* stylistic blending of datasets
* smooth interpolation between corpora
* controlled dominance of specific sources

### `max_n` behavior

The `max_n` parameter controls how N-gram sizes are used during generation:

* **`max_n > 0`**: the generator progressively builds the word using intermediate models.

  * Example with `max_n = 3`:

    * start with 2-gram (‚àÖ ‚Üí 1)
    * then 3-gram (‚àÖ,1 ‚Üí 2)
    * then 3-gram (1,2 ‚Üí 3)

* **`max_n = 0`**: the entire generated prefix is used as the key.

  * This allows free navigation across all available N-gram sizes.
  * In this mode, generation strictly follows the original training data distribution.

### Randomness and exploration

Randomness can be injected at multiple stages:

* selecting an alternative valid N-gram model
* optionally reapplying randomness during key reduction

This may produce keys that do not exist verbatim in the learned data. To preserve consistency and avoid dead ends, the reduction mechanism is always available as a fallback.

### Avoiding duplicates

To prevent generating words already present in the training database, the generator supports a **maximum retry count** (`nb_try`). If all attempts fail, generation return the last word generated.

### Seeding

Generation can be initialized using a seed:

* `custom:<string>` ‚Äî start from an explicit prefix
* `random:<n>` ‚Äî start from a random key of the selected N-gram model
  * `n = 0` selects both the model and the key randomly

### Generator API

The `Generator` is the high-level entry point. While raw N-gram and MultiGram models can be used directly, the generator:

* orchestrates model mixing
* applies intensities
* manages randomness and reduction
* checks for word existence
* applies seeding logic

‚û°Ô∏è **Pure logic only**: no I/O, no networking, no UI dependencies.

---

## üåê rs-server

`rs-server` exposes the generator through a minimal REST API built with **actix-web**. It loads models at startup and provides a stable HTTP interface for external tools and UIs.

### API endpoints

#### `GET /v1/generate`

Generate a new word using the currently loaded models and the provided options.

**Example:**

```
http://127.0.0.1:5000/v1/generate?seed=custom:test&nb_try=100
```

```
http://127.0.0.1:5000/v1/generate?max_n=0&nb_try=100&randomness=0.1&reduce_random=true&seed=random:2&intensity=french:0,fromage:100,pokemon:0,ville:52.1
```

##### Query parameters

| Parameter       | Description                                                                              |
| --------------- | ---------------------------------------------------------------------------------------- |
| `max_n`         | Maximum N-gram size (`0` = unlimited)                                                    |
| `nb_try`        | Maximum attempts to avoid generating a word already present in the database              |
| `randomness`    | Randomness factor (`0.0` ‚Äì `1.0`) controlling random N-gram selection                    |
| `reduce_random` | Apply randomness again during key reduction (highly exploratory results)                 |
| `seed`          | `custom:<string>` or `random:<n>` (model index, `0` = random)                            |
| `intensity`     | Model weights formatted as `<database>:<value>`; values are normalized before prediction |

---

#### `GET /v1/models`

Returns the list of available models loaded from the `data/` directory.

```
http://127.0.0.1:5000/v1/models
```

---

## üñ• simple-web-front

A lightweight web interface for interacting with the REST API. It is intended as a **development and experimentation tool**, not a production UI.

Features:

* interactive model intensity selection
* tuning of generation parameters
* live API testing
* visualization of generated words

The UI is deliberately minimal and may evolve over time.
